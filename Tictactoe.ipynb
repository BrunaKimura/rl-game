{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import Callback\n",
    "from spinup import ppo\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TicTacToe:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board_state = None\n",
    "\n",
    "    def set_state(self, new_state):\n",
    "        \"\"\" 2d array of cell positions of the board. 0 = cell not occupied,\n",
    "            1 = cross occupies cell, 2 = nought occupies cell.\n",
    "            Example: [\n",
    "                [0, 0, 1],\n",
    "                [0, 0, 2],\n",
    "                [0, 0, 0]\n",
    "            ] \"\"\"\n",
    "\n",
    "        new_state = np.array(new_state)\n",
    "\n",
    "        assert new_state.shape == (len(new_state), len(new_state))\n",
    "\n",
    "        self.board_state = new_state\n",
    "\n",
    "        return self.board_state\n",
    "\n",
    "    def is_finished(self):\n",
    "        \"\"\" 0 = not finished, 1 = cross win, 2 = nought win, 3 = tie \"\"\"\n",
    "\n",
    "        # Are we tied?\n",
    "        if self.board_state.flatten().tolist().count(0) == 0:\n",
    "            return 3\n",
    "\n",
    "        # Stolen: https://codereview.stackexchange.com/a/24775\n",
    "        positions_groups = (\n",
    "            [[(x, y) for y in range(self.get_board_size())] for x in range(self.get_board_size())] +  # horizontals\n",
    "            [[(x, y) for x in range(self.get_board_size())] for y in range(self.get_board_size())] +  # verticals\n",
    "            [[(d, d) for d in range(self.get_board_size())]] +  # diagonal from top-left to bottom-right\n",
    "            [[(2-d, d) for d in range(self.get_board_size())]]  # diagonal from top-right to bottom-left\n",
    "        )\n",
    "        for positions in positions_groups:\n",
    "            values = [self.board_state[x][y] for (x, y) in positions]\n",
    "            if len(set(values)) == 1 and values[0]:\n",
    "                return values[0]\n",
    "\n",
    "        # Game isn't finished\n",
    "        return 0\n",
    "\n",
    "    def get_board_size(self):\n",
    "        return len(self.board_state)\n",
    "\n",
    "    def get_turn(self):\n",
    "        \"\"\" Returns 1 for crosses turn, 2 for noughts turn \"\"\"\n",
    "\n",
    "        flattened_list = self.board_state.flatten().tolist()\n",
    "\n",
    "        if flattened_list.count(1) > flattened_list.count(2):\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def make_move(self, x, y):\n",
    "        \"\"\" Updates the state with the requested new occupied cell \"\"\"\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        \n",
    "        # Sanity check\n",
    "        assert x < self.get_board_size() and y < self.get_board_size()\n",
    "        assert self.board_state[y][x] == 0\n",
    "        assert self.is_finished() == 0\n",
    "\n",
    "        new_state = self.board_state.copy()\n",
    "        new_state[y][x] = self.get_turn()\n",
    "\n",
    "        return self.set_state(new_state)\n",
    "\n",
    "    @staticmethod\n",
    "    def translate_position_to_xy(position, board_size=3):\n",
    "        \"\"\" Takes a single number and maps it to x, y coordinates.\n",
    "            Example: 8 = 2, 2 for a board_size of 3 \"\"\"\n",
    "\n",
    "        x = position % board_size\n",
    "        y = position / board_size\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class TicTacToeEnv:\n",
    "    action_space = Discrete(3**2)\n",
    "\n",
    "    def __init__(self, board_size=3, predict_for=None):\n",
    "        self.board_size = board_size\n",
    "        self.predict_for = predict_for\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0 for cell in range(self.board_size ** 2)]),\n",
    "            high=np.array([2 for cell in range(self.board_size ** 2)])\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        if self.predict_for is not None:\n",
    "            self.tictactoe = TicTacToe()\n",
    "            self.tictactoe.set_state(self.predict_for)\n",
    "            return self.tictactoe.board_state.flatten()\n",
    "\n",
    "        self.tictactoe = TicTacToe()\n",
    "        self.tictactoe.set_state([\n",
    "            [0, 0, 0],\n",
    "            [0, 0, 0],\n",
    "            [0, 0, 0]\n",
    "        ])\n",
    "        move = self._get_random_move()\n",
    "\n",
    "        self.tictactoe.make_move(move[0], move[1])\n",
    "\n",
    "        return self.tictactoe.board_state.flatten()\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.predict_for is not None:\n",
    "            return self.tictactoe.board_state.flatten(), 0, True, {}\n",
    "\n",
    "        translated_action = TicTacToe.translate_position_to_xy(action)\n",
    "\n",
    "        try:\n",
    "            self.tictactoe.make_move(translated_action[0], translated_action[1])\n",
    "\n",
    "        except AssertionError:\n",
    "            return self.tictactoe.board_state.flatten(), -1, True, {}\n",
    "\n",
    "        reward = 0\n",
    "        done = False\n",
    "        winner = self.tictactoe.is_finished()\n",
    "        if winner == 0:\n",
    "            move = self._get_random_move()\n",
    "            self.tictactoe.make_move(move[0], move[1])\n",
    "\n",
    "            next_winner = self.tictactoe.is_finished()\n",
    "            if next_winner == 1:\n",
    "                reward = -1\n",
    "                done = True\n",
    "            elif next_winner == 3:\n",
    "                reward = 0\n",
    "                done = True\n",
    "\n",
    "        elif winner == 2:\n",
    "            reward = 1\n",
    "            done = True\n",
    "\n",
    "        elif winner == 3:\n",
    "            reward = 0\n",
    "            done = True\n",
    "\n",
    "        return self.tictactoe.board_state.flatten(), reward, done, {}\n",
    "\n",
    "    def _get_random_move(self):\n",
    "        assert self.tictactoe.is_finished() == 0\n",
    "\n",
    "        positions = []\n",
    "        for x in range(self.board_size):\n",
    "            for y in range(self.board_size):\n",
    "                if self.tictactoe.board_state[y][x] == 0:\n",
    "                    positions.append((x, y))\n",
    "\n",
    "        return positions[np.random.choice(len(positions), 1)[0]]\n",
    "\n",
    "    \n",
    "class ModelIntervalCheckpoint(Callback):\n",
    "    def __init__(self, interval, verbose=0):\n",
    "        super(ModelIntervalCheckpoint, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.step = 0\n",
    "\n",
    "        self.rewards = []\n",
    "        self.last_max = -1\n",
    "\n",
    "    def reset(self):\n",
    "        self.rewards = []\n",
    "\n",
    "    def on_step_begin(self, step, logs):\n",
    "        if self.step % self.interval == 0:\n",
    "            if len(self.rewards) > 0:\n",
    "                mean_reward = np.nanmean(self.rewards, axis=0)\n",
    "                if mean_reward > self.last_max:\n",
    "                    filename = 'saved-weights/%s.h5f' % mean_reward\n",
    "                    print(\"\\nSaving model checkpoint with mean reward %s to %s\" % (mean_reward, filename))\n",
    "\n",
    "                    self.model.save_weights(filename, overwrite=True)\n",
    "\n",
    "                    self.last_max = mean_reward\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "\n",
    "        self.rewards.append(logs['reward'])\n",
    "        self.step += 1\n",
    "        \n",
    "def predict(board_state, model_path):\n",
    "    env = TicTacToeEnv(predict_for=board_state)\n",
    "\n",
    "    dqn = build_dqn(env)\n",
    "\n",
    "    dqn.load_weights(model_path)\n",
    "\n",
    "    dqn.test(env, nb_episodes=1, visualize=False, verbose=0)\n",
    "\n",
    "    return dqn.recent_action\n",
    "\n",
    "\n",
    "def build_dqn(env):\n",
    "    nb_actions = env.action_space.n\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "\n",
    "    memory = SequentialMemory(limit=5000000, window_length=1)\n",
    "    policy = BoltzmannQPolicy()\n",
    "    log_interval = 10000\n",
    "\n",
    "    dqn = DQNAgent(\n",
    "        model=model,\n",
    "        nb_actions=nb_actions,\n",
    "        memory=memory,\n",
    "        nb_steps_warmup=1000,\n",
    "        enable_dueling_network=False,\n",
    "        target_model_update=1e-2,\n",
    "        policy=policy\n",
    "    )\n",
    "\n",
    "    dqn.compile(Adam(lr=1e-5), metrics=['accuracy', 'mae'])\n",
    "\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Log dir spinupPpo already exists! Storing info there anyway.\n",
      "\u001b[32;1mLogging data to spinupPpo/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"ac_kwargs\":\t{\n",
      "        \"activation\":\t\"relu\",\n",
      "        \"hidden_sizes\":\t[\n",
      "            64,\n",
      "            64\n",
      "        ]\n",
      "    },\n",
      "    \"actor_critic\":\t\"mlp_actor_critic\",\n",
      "    \"clip_ratio\":\t0.2,\n",
      "    \"env_fn\":\t\"<function <lambda> at 0x1227f4488>\",\n",
      "    \"epochs\":\t10,\n",
      "    \"exp_name\":\t\"experiment\",\n",
      "    \"gamma\":\t0.99,\n",
      "    \"lam\":\t0.97,\n",
      "    \"logger\":\t{\n",
      "        \"<spinup.utils.logx.EpochLogger object at 0x123b006d8>\":\t{\n",
      "            \"epoch_dict\":\t{},\n",
      "            \"exp_name\":\t\"experiment\",\n",
      "            \"first_row\":\ttrue,\n",
      "            \"log_current_row\":\t{},\n",
      "            \"log_headers\":\t[],\n",
      "            \"output_dir\":\t\"spinupPpo\",\n",
      "            \"output_file\":\t{\n",
      "                \"<_io.TextIOWrapper name='spinupPpo/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "                    \"mode\":\t\"w\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"logger_kwargs\":\t{\n",
      "        \"exp_name\":\t\"experiment\",\n",
      "        \"output_dir\":\t\"spinupPpo\"\n",
      "    },\n",
      "    \"max_ep_len\":\t1000,\n",
      "    \"pi_lr\":\t0.0003,\n",
      "    \"save_freq\":\t10,\n",
      "    \"seed\":\t0,\n",
      "    \"steps_per_epoch\":\t5000,\n",
      "    \"target_kl\":\t0.01,\n",
      "    \"train_pi_iters\":\t80,\n",
      "    \"train_v_iters\":\t80,\n",
      "    \"vf_lr\":\t0.001\n",
      "}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable pi/dense/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 31, in mlp\n    x = tf.layers.dense(x, units=h, activation=activation)\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 69, in mlp_categorical_policy\n    logits = mlp(x, list(hidden_sizes)+[act_dim], activation, None)\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 101, in mlp_actor_critic\n    pi, logp, logp_pi = policy(x, a, hidden_sizes, activation, output_activation, action_space)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-712ada9907e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogger_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spinupPpo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'experiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/ppo.py\u001b[0m in \u001b[0;36mppo\u001b[0;34m(env_fn, actor_critic, ac_kwargs, seed, steps_per_epoch, epochs, gamma, clip_ratio, pi_lr, vf_lr, train_pi_iters, train_v_iters, lam, max_ep_len, target_kl, logger_kwargs, save_freq)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Main outputs from computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mac_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Need all placeholders in *this* order later (to zip with data from buffer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\u001b[0m in \u001b[0;36mmlp_actor_critic\u001b[0;34m(x, a, hidden_sizes, activation, output_activation, policy, action_space)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\u001b[0m in \u001b[0;36mmlp_categorical_policy\u001b[0;34m(x, a, hidden_sizes, activation, output_activation, action_space)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_categorical_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mact_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mlogp_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\u001b[0m in \u001b[0;36mmlp\u001b[0;34m(x, hidden_sizes, activation, output_activation)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_activation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/layers/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 _reuse=reuse)\n\u001b[0;32m--> 188\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \"\"\"\n\u001b[0;32m-> 1227\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[0;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    605\u001b[0m     new_variable = getter(\n\u001b[1;32m    606\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" % (err_msg, \"\".join(\n\u001b[0;32m--> 848\u001b[0;31m             traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable pi/dense/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 31, in mlp\n    x = tf.layers.dense(x, units=h, activation=activation)\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 69, in mlp_categorical_policy\n    logits = mlp(x, list(hidden_sizes)+[act_dim], activation, None)\n  File \"/Users/raphacosta/Desktop/Insper7/machineLearning/projeto/spinningup/spinup/algos/ppo/core.py\", line 101, in mlp_actor_critic\n    pi, logp, logp_pi = policy(x, a, hidden_sizes, activation, output_activation, action_space)\n"
     ]
    }
   ],
   "source": [
    "env_fn = lambda : TicTacToeEnv()\n",
    "\n",
    "ac_kwargs = dict(hidden_sizes=[64,64], activation=tf.nn.relu)\n",
    "\n",
    "logger_kwargs = dict(output_dir='spinupPpo', exp_name='experiment')\n",
    "\n",
    "ppo(env_fn=env_fn, ac_kwargs=ac_kwargs, steps_per_epoch=5000, epochs=10, logger_kwargs=logger_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./spinupPpo/simple_save/variables/variables\n",
      "Using default action op.\n",
      "\u001b[32;1mLogging data to /tmp/experiments/1558644139/progress.txt\u001b[0m\n",
      "Episode 0 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 1 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 2 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 3 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 4 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 5 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 6 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 7 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 8 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 9 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 10 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 11 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 12 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 13 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 14 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 15 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 16 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 17 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 18 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 19 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 20 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 21 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 22 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 23 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 24 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 25 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 26 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 27 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 28 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 29 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 30 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 31 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 32 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 33 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 34 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 35 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 36 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 37 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 38 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 39 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 40 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 41 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 42 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 43 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 44 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 45 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 46 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 47 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 48 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 49 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 50 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 51 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 52 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 53 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 54 \t EpRet -1.000 \t EpLen 1\n",
      "Episode 55 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 56 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 57 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 58 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 59 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 60 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 61 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 62 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 63 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 64 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 65 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 66 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 67 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 68 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 69 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 70 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 71 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 72 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 73 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 74 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 75 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 76 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 77 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 78 \t EpRet -1.000 \t EpLen 4\n",
      "Episode 79 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 80 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 81 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 82 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 83 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 84 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 85 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 86 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 87 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 88 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 89 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 90 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 91 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 92 \t EpRet 1.000 \t EpLen 3\n",
      "Episode 93 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 94 \t EpRet -1.000 \t EpLen 3\n",
      "Episode 95 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 96 \t EpRet 0.000 \t EpLen 4\n",
      "Episode 97 \t EpRet -1.000 \t EpLen 2\n",
      "Episode 98 \t EpRet 1.000 \t EpLen 4\n",
      "Episode 99 \t EpRet 0.000 \t EpLen 4\n",
      "-------------------------------------\n",
      "|    AverageEpRet |            -0.2 |\n",
      "|        StdEpRet |            0.86 |\n",
      "|        MaxEpRet |               1 |\n",
      "|        MinEpRet |              -1 |\n",
      "|           EpLen |             3.3 |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spinup.utils.test_policy import load_policy, run_policy\n",
    "_, get_action = load_policy('./spinupPpo')\n",
    "# env = env_fn.make()\n",
    "env = TicTacToeEnv()\n",
    "run_policy(env, get_action, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions, activation='linear'))\n",
    "\n",
    "memory = SequentialMemory(limit=5000000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "log_interval = 10000\n",
    "\n",
    "dqn = DQNAgent(\n",
    "    model=model,\n",
    "    nb_actions=nb_actions,\n",
    "    memory=memory,\n",
    "    nb_steps_warmup=1000,\n",
    "    enable_dueling_network=False,\n",
    "    target_model_update=1e-2,\n",
    "    policy=policy\n",
    ")\n",
    "\n",
    "dqn.compile(Adam(lr=1e-5), metrics=['accuracy', 'mae'])\n",
    "\n",
    "# dqn.fit(env, nb_steps=50000, visualize=False, verbose=1,\n",
    "#     callbacks=[ModelIntervalCheckpoint(interval=log_interval)],\n",
    "#     log_interval=log_interval\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_state = np.array([\n",
    "            [1, 0, 2],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 0]\n",
    "        ])\n",
    "predict(board_state, 'saved-weights/-0.141.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
